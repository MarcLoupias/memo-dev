(window.webpackJsonp=window.webpackJsonp||[]).push([[30],{198:function(e,t,r){"use strict";r.r(t);var a=r(0),n=Object(a.a)({},(function(){var e=this,t=e._self._c;return t("div",{staticClass:"content"},[e._m(0),e._v(" "),e._m(1),e._v(" "),t("p",[t("a",{attrs:{href:"https://www.youtube.com/watch?v=ZbWL2W53BXY",target:"_blank",rel:"noopener noreferrer"}},[e._v("Comprendre et utiliser les modèles de langage d'IA (Sébastien COLLET) - Devoxx 2023"),t("OutboundLink")],1)]),e._v(" "),e._m(2),e._v(" "),t("p",[t("a",{attrs:{href:"https://www.linkedin.com/feed/update/urn:li:activity:7133567569684238336/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Yann LeCun about IA training on LinkedIn"),t("OutboundLink")],1)]),e._v(" "),e._m(3),t("p",[e._v("TLDR : Next gen IA needs to use video instead of text.")]),e._v(" "),t("p",[e._v("To compare, see "),t("a",{attrs:{href:"https://www.youtube.com/watch?v=Kv4FzAdxclA",target:"_blank",rel:"noopener noreferrer"}},[e._v("this Jean-Baptiste Kempf (VLC) interview about how video works"),t("OutboundLink")],1),e._v(".")]),e._v(" "),e._m(4),e._v(" "),t("p",[e._v("Each CODEC behave the same way, they delete data not seen by eyes, and they seek data blocks that are redundant image by image or between images.")]),e._v(" "),e._m(5),t("ul",[t("li",[e._v("H.264 is the most common CODEC used in the world, around 80% of usage.")]),e._v(" "),t("li",[e._v("HEVC is crippled by royalties, it remains unused on the web instead of television, around 5%.")]),e._v(" "),t("li",[e._v("VP9 created by Google, royalty free, opensource, Youtube and Facebook uses it.")]),e._v(" "),t("li",[e._v("AV1 then AV2 created by the Open Media Alliance initiated by Google.")]),e._v(" "),t("li",[e._v("AV1 is implemented by "),t("a",{attrs:{href:"https://github.com/videolan/dav1d",target:"_blank",rel:"noopener noreferrer"}},[e._v("Dav1d"),t("OutboundLink")],1),e._v(", a VLC project, around 210K assembly LoC + 30K C LoC. This impl is widely used by GAFAM.")])]),e._v(" "),e._m(6),e._v(" "),t("p",[t("a",{attrs:{href:"https://gen-ai.fr/outils/generation-code/chatgpt-pour-developpeurs/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Guide ChatGPT pour développeurs"),t("OutboundLink")],1)]),e._v(" "),t("p",[t("a",{attrs:{href:"https://www.frenchweb.fr/vocabulaire-de-lintelligence-artificielle-12-termes-a-connaitre/307870",target:"_blank",rel:"noopener noreferrer"}},[e._v("vocabulaire : www.frenchweb.fr"),t("OutboundLink")],1)]),e._v(" "),t("p",[t("a",{attrs:{href:"https://www.franceculture.fr/numerique/aux-origines-de-lintelligence-artificielle",target:"_blank",rel:"noopener noreferrer"}},[e._v("Aux origines de l'intelligence artificielle - www.franceculture.fr - 20180331"),t("OutboundLink")],1)]),e._v(" "),t("p",[t("a",{attrs:{href:"https://ai.google/research/pubs/pub43146",target:"_blank",rel:"noopener noreferrer"}},[e._v("Machine Learning: The High Interest Credit Card of Technical Debt - 2014"),t("OutboundLink")],1)]),e._v(" "),e._m(7),e._v(" "),t("p",[e._v("Took from "),t("a",{attrs:{href:"https://www.funfunforum.com/t/machine-learning-and-tech-debt-a-publication-from-google/5221",target:"_blank",rel:"noopener noreferrer"}},[e._v("Machine learning and tech debt: A publication from Google on www.funfunforum.com"),t("OutboundLink")],1),e._v(" :")]),e._v(" "),e._m(8),e._v(" "),t("p",[t("a",{attrs:{href:"https://www.futuretimeline.net/21stcentury/images/future-timeline-technology-singularity.jpg",target:"_blank",rel:"noopener noreferrer"}},[e._v("Exponential growth of supercomputing power, 1995-2060 (logarithmic scale)"),t("OutboundLink")],1)]),e._v(" "),t("p",[t("a",{attrs:{href:"https://www.futuretimeline.net/blog/2018/09/25.htm",target:"_blank",rel:"noopener noreferrer"}},[e._v('Human-level artificial intelligence could be achieved "within five to ten years", say experts - www.futuretimeline.net - 20180925'),t("OutboundLink")],1)]),e._v(" "),t("p",[t("a",{attrs:{href:"https://www.franceculture.fr/emissions/dimanche-et-apres/sante-nos-donnees-personnelles-peuvent-elles-sauver-des-vies",target:"_blank",rel:"noopener noreferrer"}},[e._v("Santé : nos données personnelles peuvent-elles sauver des vies ?"),t("OutboundLink")],1)]),e._v(" "),e._m(9),e._v(" "),t("p",[t("a",{attrs:{href:"https://www.youtube.com/watch?v=VzeOnBRzDik",target:"_blank",rel:"noopener noreferrer"}},[e._v("Éric Sadin : l'asservissement par l'Intelligence Artificielle ? - Thinkerview - 20181108"),t("OutboundLink")],1)]),e._v(" "),e._m(10),e._v(" "),t("p",[t("a",{attrs:{href:"https://www.youtube.com/watch?v=3GGEKRS4KMo",target:"_blank",rel:"noopener noreferrer"}},[e._v("\"Ce n'est pas possible d'éviter les erreurs de l'IA\", affirme Luc Julia - 20231220"),t("OutboundLink")],1)]),e._v(" "),e._m(11),e._v(" "),e._m(12),e._v(" "),t("p",[t("a",{attrs:{href:"https://www.tensorflow.org/?hl=fr",target:"_blank",rel:"noopener noreferrer"}},[e._v("TensorFlow"),t("OutboundLink")],1)]),e._v(" "),t("p",[t("a",{attrs:{href:"https://pytorch.org/",target:"_blank",rel:"noopener noreferrer"}},[e._v("PyTorch"),t("OutboundLink")],1)]),e._v(" "),t("p",[t("a",{attrs:{href:"https://huggingface.co/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Hugging Face"),t("OutboundLink")],1)]),e._v(" "),e._m(13),e._v(" "),e._m(14),e._v(" "),e._m(15),e._v(" "),t("p",[t("a",{attrs:{href:"https://www.youtube.com/watch?v=5mmjig68d40",target:"_blank",rel:"noopener noreferrer"}},[e._v("Get Started with Mistral 7B Locally in 6 Minutes"),t("OutboundLink")],1)]),e._v(" "),e._m(16),e._v(" "),e._m(17),e._v(" "),t("p",[t("a",{attrs:{href:"https://jan.ai/",target:"_blank",rel:"noopener noreferrer"}},[t("code",[e._v("https://jan.ai/")]),t("OutboundLink")],1),e._v(" "),t("a",{attrs:{href:"https://github.com/janhq/jan",target:"_blank",rel:"noopener noreferrer"}},[t("code",[e._v("janhq/jan")]),e._v(" - "),t("code",[e._v("github.com")]),t("OutboundLink")],1)]),e._v(" "),t("p",[t("a",{attrs:{href:"https://www.youtube.com/watch?v=iVYP2lyreAA",target:"_blank",rel:"noopener noreferrer"}},[e._v("L'IA enfin libérée ! Un ChatGPT gratuit, local et open source"),t("OutboundLink")],1)]),e._v(" "),e._m(18),e._v(" "),t("p",[t("a",{attrs:{href:"https://github.com/mistralai",target:"_blank",rel:"noopener noreferrer"}},[t("code",[e._v("github.com/mistralai")]),t("OutboundLink")],1)]),e._v(" "),t("p",[t("a",{attrs:{href:"https://docs.mistral.ai/",target:"_blank",rel:"noopener noreferrer"}},[t("code",[e._v("docs.mistral.ai")]),t("OutboundLink")],1),e._v(" "),t("a",{attrs:{href:"https://github.com/mistralai/platform-docs-public",target:"_blank",rel:"noopener noreferrer"}},[e._v("doc source code"),t("OutboundLink")],1)]),e._v(" "),t("p",[t("a",{attrs:{href:"https://github.com/mistralai/client-js",target:"_blank",rel:"noopener noreferrer"}},[t("code",[e._v("mistralai/client-js")]),e._v(" - "),t("code",[e._v("github.com")]),t("OutboundLink")],1)]),e._v(" "),e._m(19)])}),[function(){var e=this._self._c;return e("h1",{attrs:{id:"ia"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#ia"}},[this._v("#")]),this._v(" IA")])},function(){var e=this._self._c;return e("h2",{attrs:{id:"usage"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#usage"}},[this._v("#")]),this._v(" usage")])},function(){var e=this._self._c;return e("h2",{attrs:{id:"training"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#training"}},[this._v("#")]),this._v(" training")])},function(){var e=this,t=e._self._c;return t("div",{staticClass:"language-text line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v("Animals and humans get very smart very quickly with vastly smaller amounts of training data than current AI systems.\n\nCurrent LLMs are trained on text data that would take 20,000 years for a human to read.\nAnd still, they haven't learned that if A is the same as B, then B is the same as A.\nHumans get a lot smarter than that with comparatively little training data.\nEven corvids, parrots, dogs, and octopuses get smarter than that very, very quickly, with only 2 billion neurons and a few trillion \"parameters.\"\n\nMy money is on new architectures that would learn as efficiently as animals and humans.\nUsing more text data (synthetic or not) is a temporary stopgap made necessary by the limitations of our current approaches.\nThe salvation is in using sensory data, e.g. video, which has higher bandwidth and more internal structure.\n\nThe total amount of visual data seen by a 2 year-old is larger than the amount of data used to train LLMs, but still pretty reasonable.\n2 years = 2x365x12x3600 or roughly 32 million seconds.\nWe have 2 million optical nerve fibers, carrying roughly ten bytes per second each.\nThat's a total of 6E14 bytes. The volume of data for LLM training is typically 1E13 tokens, which is about 2E13 bytes.\nIt's a factor of 30.\n\nImportantly, there is more to learn from video than from text because it is more redundant.\nIt tells you a lot about the structure of the world.\n")])]),e._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[e._v("1")]),t("br"),t("span",{staticClass:"line-number"},[e._v("2")]),t("br"),t("span",{staticClass:"line-number"},[e._v("3")]),t("br"),t("span",{staticClass:"line-number"},[e._v("4")]),t("br"),t("span",{staticClass:"line-number"},[e._v("5")]),t("br"),t("span",{staticClass:"line-number"},[e._v("6")]),t("br"),t("span",{staticClass:"line-number"},[e._v("7")]),t("br"),t("span",{staticClass:"line-number"},[e._v("8")]),t("br"),t("span",{staticClass:"line-number"},[e._v("9")]),t("br"),t("span",{staticClass:"line-number"},[e._v("10")]),t("br"),t("span",{staticClass:"line-number"},[e._v("11")]),t("br"),t("span",{staticClass:"line-number"},[e._v("12")]),t("br"),t("span",{staticClass:"line-number"},[e._v("13")]),t("br"),t("span",{staticClass:"line-number"},[e._v("14")]),t("br"),t("span",{staticClass:"line-number"},[e._v("15")]),t("br"),t("span",{staticClass:"line-number"},[e._v("16")]),t("br"),t("span",{staticClass:"line-number"},[e._v("17")]),t("br"),t("span",{staticClass:"line-number"},[e._v("18")]),t("br"),t("span",{staticClass:"line-number"},[e._v("19")]),t("br")])])},function(){var e=this,t=e._self._c;return t("ul",[t("li",[e._v("an image is an array of pixel, each pixel is a color")]),e._v(" "),t("li",[e._v("a video is a collection of images (something between 24 to 60 images per second)")]),e._v(" "),t("li",[e._v("CODEC = compression decompression algorithm to send video.")]),e._v(" "),t("li",[e._v("Video pixel by pixel is around 10 to 40 Gb/s")]),e._v(" "),t("li",[e._v("the goal of CODEC is to divide 100, 200, ... 1K the bandwith used.")]),e._v(" "),t("li",[e._v("dividing bandwith is destroying information")]),e._v(" "),t("li",[e._v("the tech behind is based on how the human eyes behave, some colors are better seen then others, so we can delete some colors without downgrading the image seen.")])])},function(){var e=this._self._c;return e("div",{staticClass:"language-text line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[this._v("MPEG-1 (1993) ---\x3e MPEG-2 (1995) = DVD ---\x3e DIVX (1999) (=MPEG-4) ---\x3e H.264 (2003) ---\x3e HEVC (2013) ---\x3e VP9 (2013)\n")])]),this._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[this._v("1")]),e("br")])])},function(){var e=this._self._c;return e("h2",{attrs:{id:"misc"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#misc"}},[this._v("#")]),this._v(" misc")])},function(){var e=this._self._c;return e("blockquote",[e("p",[this._v("Machine learning offers a fantastically powerful toolkit for building complex systems quickly. This paper argues that it is dangerous to think of these quick wins as coming for free. Using the framework of technical debt, we note that it is remarkably easy to incur massive ongoing maintenance costs at the system level when applying machine learning. The goal of this paper is highlight several machine learning specific risk factors and design patterns to be avoided or refactored where possible. These include boundary erosion, entanglement, hidden feedback loops, undeclared consumers, data dependencies, changes in the external world, and a variety of system-level anti-patterns.")])])},function(){var e=this._self._c;return e("blockquote",[e("p",[this._v("Another worry for real-world systems lies in hidden feedback loops. Systems that learn from world behavior are clearly intended to be part of a feedback loop. For example, a system for predicting the click through rate (CTR) of news headlines on a website likely relies on user clicks as training labels, which in turn depend on previous predictions from the model. This leads to issues in analyzing system performance, but these are the obvious kinds of statistical challenges that machine learning researchers may find natural to investigate [2].")])])},function(){var e=this._self._c;return e("blockquote",[e("p",[this._v("38:20 Les dossiers patients se vendent entre 100 et 150 euros l'unité sur le darkweb (pour feed les IA du domaine médical)")])])},function(){var e=this._self._c;return e("blockquote",[e("p",[this._v("objectif du dev de l'IA par les GAFA est de supprimer le libre arbitre par l'analyse des états successifs de l'individu pour lui proposer des choix")])])},function(){var e=this._self._c;return e("blockquote",[e("p",[this._v("Eric Julia, co-créateur de SIRI, interview France Inter")])])},function(){var e=this._self._c;return e("h2",{attrs:{id:"tools"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#tools"}},[this._v("#")]),this._v(" tools")])},function(){var e=this._self._c;return e("blockquote",[e("p",[this._v("outils liés au ML + hub d'outils et de modèles")])])},function(){var e=this._self._c;return e("h2",{attrs:{id:"ia-self-hosting"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#ia-self-hosting"}},[this._v("#")]),this._v(" ia self-hosting")])},function(){var e=this._self._c;return e("h3",{attrs:{id:"articles"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#articles"}},[this._v("#")]),this._v(" articles")])},function(){var e=this._self._c;return e("h3",{attrs:{id:"solutions"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#solutions"}},[this._v("#")]),this._v(" solutions")])},function(){var e=this._self._c;return e("h4",{attrs:{id:"jan-ai"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#jan-ai"}},[this._v("#")]),this._v(" "),e("code",[this._v("jan.ai")])])},function(){var e=this._self._c;return e("h3",{attrs:{id:"mistral"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#mistral"}},[this._v("#")]),this._v(" mistral")])},function(){var e=this._self._c;return e("blockquote",[e("p",[this._v("You can use the Mistral JavaScript client to interact with the Mistral AI API.")])])}],!1,null,null,null);t.default=n.exports}}]);